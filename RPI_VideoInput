#!/usr/bin/env python3
import os
import torch
import cv2
from ultralytics import YOLO
import time
import tkinter as tk
from tkinter import filedialog
import threading
import queue

# -------------------------- Fix for PyTorch 2.6+ weights loading --------------------------
orig_torch_load = torch.load
def torch_load_wrapper(*args, **kwargs):
    kwargs["weights_only"] = False
    return orig_torch_load(*args, **kwargs)
torch.load = torch_load_wrapper

# -------------------------- MODEL PATHS (fill these with your .pt files on the Pi) ----------
PIG_MODEL_PATH = "/home/asfrotect/Projects/pig_vs_non_pig.v3.pt"
ASF_MODEL_PATH = "/home/asfrotect/Projects/best(ASF_MODEL)_.pt"
BEHAVIOR_MODEL_PATH = "/home/asfrotect/Projects/best(BEHAVIOR_MODEL)_.pt"

# -------------------------- Choose video file via file dialog --------------------------
def choose_video_file():
    root = tk.Tk()
    root.withdraw()  # hide main window
    root.attributes("-topmost", True)  # bring dialog on top
    file_path = filedialog.askopenfilename(
        title="Select video file",
        filetypes=[("Video files", "*.mp4 *.avi *.mov *.mkv"), ("All files", "*.*")]
    )
    root.destroy()
    return file_path

video_path = choose_video_file()
if not video_path:
    print("No video file selected. Exiting.")
    exit()

if not os.path.isfile(video_path):
    print(f"Selected file does not exist: {video_path}")
    exit()

print(f"Selected video: {video_path}")

# -------------------------- Load YOLOv8 models (only if paths provided) ----------
def load_model_or_none(path, model_name):
    if path and os.path.isfile(path):
        print(f"Loading {model_name} model from: {path}")
        return YOLO(path)
    else:
        print(f"[WARN] {model_name} model path not provided or file missing. {model_name} detection will be skipped.")
        return None

pig_model = load_model_or_none(PIG_MODEL_PATH, "Pig")
asf_model = load_model_or_none(ASF_MODEL_PATH, "ASF")
behavior_model = load_model_or_none(BEHAVIOR_MODEL_PATH, "Behavior")

if pig_model is None:
    print("Error: Pig model is required. Put your pig model path in PIG_MODEL_PATH and restart.")
    exit()

# -------------------------- Open video file ----------
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("Error: Could not open video file.")
    exit()

# -------------------------- Helper functions --------------------------
def draw_label(frame, box, label, color=(0,255,0)):
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    # Put text with background for readability
    (w_text, h_text), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
    cv2.rectangle(frame, (x1, y1 - h_text - 8), (x1 + w_text + 6, y1), color, -1)
    cv2.putText(frame, label, (x1 + 3, y1 - 4),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)

def box_inside(boxA, boxB):
    ax1, ay1, ax2, ay2 = map(int, boxA)
    bx1, by1, bx2, by2 = map(int, boxB)
    return ax1 >= bx1 and ay1 >= by1 and ax2 <= bx2 and ay2 <= by2

# -------------------------- Detection scheduling + worker --------------------------
DETECTION_INTERVAL = 3.0  # seconds: run detection every 3s
detection_queue = queue.Queue(maxsize=1)  # hold 1 frame to detect (drop-old)
annotated_lock = threading.Lock()
annotated_boxes = []   # list of tuples: (box_coords, label, color)
expiry_time = 0.0
running = True

def detection_worker():
    global annotated_boxes, expiry_time, running
    while running:
        try:
            frame_for_detection = detection_queue.get(timeout=0.5)
        except queue.Empty:
            continue

        # ensure 3-channel uint8
        src = frame_for_detection
        if src.ndim == 3 and src.shape[2] == 4:
            src = src[..., :3]
        src = src.astype('uint8')

        boxes_out = []  # collect (x1,y1,x2,y2,label,color)

        # ---------- Step 1: Detect pigs ----------
        pig_results = pig_model.predict(source=src, conf=0.3, save=False, show=False, verbose=False)
        pig_boxes = []
        for r in pig_results:
            for box in r.boxes:
                try:
                    cls_id = int(box.cls[0].item()); conf = float(box.conf[0].item())
                except Exception:
                    cls_id = int(box.cls); conf = float(box.conf)
                if conf < 0.3:
                    continue
                label = r.names.get(cls_id, str(cls_id)) if hasattr(r, "names") else str(cls_id)
                if "pig" in label.lower():
                    pig_boxes.append((box, conf))

        # ---------- Step 2: For each pig, detect ASF and behavior ----------
        for pig_box, pig_conf in pig_boxes:
            x1, y1, x2, y2 = map(int, pig_box.xyxy[0])
            h_frame, w_frame = src.shape[:2]
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w_frame - 1, x2), min(h_frame - 1, y2)
            pig_crop = src[y1:y2, x1:x2]
            if pig_crop.size == 0:
                continue

            # ASF detection
            lesion_boxes = []
            part_boxes = []
            if asf_model is not None:
                asf_results = asf_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                for r in asf_results:
                    for a_box in r.boxes:
                        try:
                            cls_id = int(a_box.cls[0].item()); conf = float(a_box.conf[0].item())
                        except Exception:
                            cls_id = int(a_box.cls); conf = float(a_box.conf)
                        if conf < 0.5:
                            continue
                        label = r.names[cls_id]
                        ax1, ay1, ax2, ay2 = map(int, a_box.xyxy[0])
                        ax1, ay1, ax2, ay2 = ax1 + x1, ay1 + y1, ax2 + x1, ay2 + y1
                        if "lesion" in label.lower():
                            lesion_boxes.append((ax1, ay1, ax2, ay2))
                        elif label.lower() in ["ear", "leg", "nose", "tail"]:
                            part_boxes.append((ax1, ay1, ax2, ay2, label))

            # Behavior detection
            behavior_label = None
            if behavior_model is not None:
                behavior_results = behavior_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                for r in behavior_results:
                    for b_box in r.boxes:
                        try:
                            cls_id = int(b_box.cls[0].item()); conf = float(b_box.conf[0].item())
                        except Exception:
                            cls_id = int(b_box.cls); conf = float(b_box.conf)
                        if conf >= 0.5:
                            behavior_label = r.names[cls_id]
                            break
                    if behavior_label:
                        break

            behavior_label_full = f"pig-{pig_conf:.2f}-{behavior_label.lower()}" if behavior_label else f"pig-{pig_conf:.2f}"

            # append pig box + behavior label (green)
            boxes_out.append(((x1, y1, x2, y2), behavior_label_full, (0,255,0)))

            # append lesion boxes (red) with merged labels if overlapping parts
            for lesion in lesion_boxes:
                merged_label = "possible skin lesion"
                for (px1, py1, px2, py2, part_label) in part_boxes:
                    if box_inside(lesion, (px1, py1, px2, py2)):
                        merged_label = f"possible skin lesion - {part_label.lower()}"
                        break
                boxes_out.append((lesion, merged_label, (0,0,255)))

        # store results and set expiry
        with annotated_lock:
            annotated_boxes = boxes_out
            expiry_time = time.time() + DETECTION_INTERVAL  # keep boxes visible for DETECTION_INTERVAL seconds

        try:
            detection_queue.task_done()
        except Exception:
            pass

# start worker thread
worker = threading.Thread(target=detection_worker, daemon=True)
worker.start()

# -------------------------- Main processing loop (display every frame) --------------------------
frame_count = 0
fps_time = time.time()

last_detection_request = 0.0

try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("End of video or failed to read frame.")
            break

        frame_count += 1

        im_bgr = frame.copy()

        # If annotated boxes are still valid (not expired), draw them
        now = time.time()
        with annotated_lock:
            current_boxes = annotated_boxes.copy()
            current_expiry = expiry_time

        if now <= current_expiry and current_boxes:
            for (box_coords, label, color) in current_boxes:
                draw_label(im_bgr, box_coords, label, color=color)

        # Display FPS (display FPS measured per displayed frame)
        now2 = time.time()
        fps = 1.0 / (now2 - fps_time) if (now2 - fps_time) > 0 else 0.0
        fps_time = now2
        cv2.putText(im_bgr, f"FPS: {fps:.1f}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)

        cv2.imshow("Pig + ASF + Behavior Detection", im_bgr)

        # If it's time to request a detection (every DETECTION_INTERVAL seconds), push latest frame (non-blocking)
        if (now - last_detection_request) >= DETECTION_INTERVAL:
            try:
                # drop old queued frame if exists, keep latest
                if detection_queue.full():
                    try:
                        _ = detection_queue.get_nowait()
                        detection_queue.task_done()
                    except Exception:
                        pass
                detection_queue.put_nowait(frame.copy())
                last_detection_request = now
            except queue.Full:
                pass

        # Press ESC to exit early
        if cv2.waitKey(1) & 0xFF == 27:
            break

finally:
    running = False
    try:
        while not detection_queue.empty():
            detection_queue.get_nowait()
            detection_queue.task_done()
    except Exception:
        pass

    worker.join(timeout=1.0)
    cap.release()
    cv2.destroyAllWindows()
    print("Exited cleanly.")
