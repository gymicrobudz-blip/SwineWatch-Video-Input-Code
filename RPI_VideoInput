#!/usr/bin/env python3
import os
import torch
import cv2
from ultralytics import YOLO
import time
import tkinter as tk
from tkinter import filedialog
import threading
import queue

# -------------------------- Fix for PyTorch 2.6+ weights loading --------------------------
orig_torch_load = torch.load
def torch_load_wrapper(*args, **kwargs):
    kwargs["weights_only"] = False
    return orig_torch_load(*args, **kwargs)
torch.load = torch_load_wrapper

# -------------------------- MODEL PATHS (fill these with your .pt files on the Pi) ----------
PIG_MODEL_PATH = "/home/asfrotect/Projects/pig_vs_non_pig.v3.pt"
ASF_MODEL_PATH = "/home/asfrotect/Projects/best(ASF_MODEL)_.pt"
BEHAVIOR_MODEL_PATH = "/home/asfrotect/Projects/best(BEHAVIOR_MODEL)_.pt"

# -------------------------- Choose video file via file dialog --------------------------
def choose_video_file():
    root = tk.Tk()
    root.withdraw()
    root.attributes("-topmost", True)
    file_path = filedialog.askopenfilename(
        title="Select video file",
        filetypes=[("Video files", "*.mp4 *.avi *.mov *.mkv"), ("All files", "*.*")]
    )
    root.destroy()
    return file_path

video_path = choose_video_file()
if not video_path:
    print("No video file selected. Exiting.")
    exit()

if not os.path.isfile(video_path):
    print(f"Selected file does not exist: {video_path}")
    exit()

print(f"Selected video: {video_path}")

# -------------------------- Load YOLOv8 models (only if paths provided) ----------
def load_model_or_none(path, model_name):
    if path and os.path.isfile(path):
        print(f"Loading {model_name} model from: {path}")
        return YOLO(path)
    else:
        print(f"[WARN] {model_name} model path not provided or file missing. {model_name} detection will be skipped.")
        return None

pig_model = load_model_or_none(PIG_MODEL_PATH, "Pig")
asf_model = load_model_or_none(ASF_MODEL_PATH, "ASF")
behavior_model = load_model_or_none(BEHAVIOR_MODEL_PATH, "Behavior")

if pig_model is None:
    print("Error: Pig model is required. Put your pig model path in PIG_MODEL_PATH and restart.")
    exit()

# -------------------------- Open video file ----------
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("Error: Could not open video file.")
    exit()

# -------------------------- Helper functions (unchanged drawing logic) ----------
def draw_label(frame, box, label, color=(0,255,0)):
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    (w_text, h_text), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
    cv2.rectangle(frame, (x1, y1 - h_text - 8), (x1 + w_text + 6, y1), color, -1)
    cv2.putText(frame, label, (x1 + 3, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)

def box_inside(boxA, boxB):
    ax1, ay1, ax2, ay2 = map(int, boxA)
    bx1, by1, bx2, by2 = map(int, boxB)
    return ax1 >= bx1 and ay1 >= by1 and ax2 <= bx2 and ay2 <= by2

# -------------------------- Threading infra (ADDED) --------------------------
frame_queue = queue.Queue(maxsize=1)      # keep only latest frame for inference
annotated_frame_lock = threading.Lock()
annotated_frame = None                     # will hold latest annotated frame for display
running = True

# FPS measurement for display
display_fps_time = time.time()
display_fps = 0.0

# If you want to run ASF/behavior less often, set detection_interval_seconds > 0.
# If you want full detection every frame, set detection_interval_seconds = 0
detection_interval_seconds = 0.0  # 0.0 = run ASF+Behavior every worker run (default). Set to 5.0 to run every 5s.

def inference_worker():
    global annotated_frame, running, display_fps_time, display_fps
    last_detection_time = 0.0
    while running:
        try:
            frame = frame_queue.get(timeout=0.5)
        except queue.Empty:
            continue

        src = frame
        if src.ndim == 3 and src.shape[2] == 4:
            src = src[..., :3]
        src = src.astype('uint8')

        im_bgr = src.copy()

        # ---------- Pig detection (same logic) ----------
        pig_results = pig_model.predict(source=src, conf=0.3, save=False, show=False, verbose=False)
        pig_boxes = []
        for r in pig_results:
            for box in r.boxes:
                try:
                    cls_id = int(box.cls[0].item()); conf = float(box.conf[0].item())
                except Exception:
                    cls_id = int(box.cls); conf = float(box.conf)
                if conf < 0.3:
                    continue
                label = r.names.get(cls_id, str(cls_id)) if hasattr(r, "names") else str(cls_id)
                if "pig" in label.lower():
                    pig_boxes.append((box, conf))

        now = time.time()
        do_heavy = False
        if detection_interval_seconds <= 0.0:
            do_heavy = True
        else:
            if (now - last_detection_time) >= detection_interval_seconds:
                do_heavy = True

        # If not running heavy this round, we'll skip ASF/behavior and reuse previous annotations.
        # For simplicity we still draw pig boxes/labels per frame here.
        # ---------- ASF + Behavior (kept same when executed) ----------
        for pig_box, pig_conf in pig_boxes:
            x1, y1, x2, y2 = map(int, pig_box.xyxy[0])
            h_frame, w_frame = src.shape[:2]
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w_frame - 1, x2), min(h_frame - 1, y2)
            pig_crop = src[y1:y2, x1:x2]
            if pig_crop.size == 0:
                continue

            lesion_boxes = []
            part_boxes = []
            behavior_label = None

            if do_heavy and asf_model is not None:
                asf_results = asf_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                for r in asf_results:
                    for a_box in r.boxes:
                        try:
                            cls_id = int(a_box.cls[0].item()); conf = float(a_box.conf[0].item())
                        except Exception:
                            cls_id = int(a_box.cls); conf = float(a_box.conf)
                        if conf < 0.5: continue
                        label = r.names[cls_id]
                        ax1, ay1, ax2, ay2 = map(int, a_box.xyxy[0])
                        ax1, ay1, ax2, ay2 = ax1 + x1, ay1 + y1, ax2 + x1, ay2 + y1
                        if "lesion" in label.lower():
                            lesion_boxes.append((ax1, ay1, ax2, ay2))
                        elif label.lower() in ["ear", "leg", "nose", "tail"]:
                            part_boxes.append((ax1, ay1, ax2, ay2, label))

            if do_heavy and behavior_model is not None:
                behavior_results = behavior_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                for r in behavior_results:
                    for b_box in r.boxes:
                        try:
                            cls_id = int(b_box.cls[0].item()); conf = float(b_box.conf[0].item())
                        except Exception:
                            cls_id = int(b_box.cls); conf = float(b_box.conf)
                        if conf >= 0.5:
                            behavior_label = r.names[cls_id]
                            break
                    if behavior_label: break

            behavior_label_full = f"pig-{pig_conf:.2f}-{behavior_label.lower()}" if behavior_label else f"pig-{pig_conf:.2f}"

            # Draw ASF lesions (if any)
            for lesion in lesion_boxes:
                merged_label = "possible skin lesion"
                for (px1, py1, px2, py2, part_label) in part_boxes:
                    if box_inside(lesion, (px1, py1, px2, py2)):
                        merged_label = f"possible skin lesion - {part_label.lower()}"
                        break
                draw_label(im_bgr, lesion, merged_label, color=(0,0,255))

            # Draw pig + behavior label
            draw_label(im_bgr, (x1, y1, x2, y2), behavior_label_full, color=(0,255,0))

        if do_heavy:
            last_detection_time = now

        # overlay display FPS (measured here for annotated frames)
        now2 = time.time()
        display_fps = 1.0 / (now2 - display_fps_time) if (now2 - display_fps_time) > 0 else 0.0
        display_fps_time = now2
        cv2.putText(im_bgr, f"FPS: {display_fps:.1f}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)

        # store annotated frame for main thread to display
        with annotated_frame_lock:
            annotated_frame = im_bgr

        try:
            frame_queue.task_done()
        except Exception:
            pass

# start worker thread
worker = threading.Thread(target=inference_worker, daemon=True)
worker.start()

# -------------------------- Main loop (modified) --------------------------
try:
    print("Processing. Press ESC to stop.")
    while True:
        ret, frame = cap.read()
        if not ret:
            print("End of video or failed to read frame.")
            break

        # show latest annotated frame if available, otherwise show raw frame
        with annotated_frame_lock:
            disp = annotated_frame.copy() if annotated_frame is not None else frame.copy()

        cv2.imshow("Pig + ASF + Behavior Detection", disp)

        # Non-blocking push to queue: drop the old frame if queue full so worker always gets latest
        try:
            if frame_queue.full():
                try:
                    _ = frame_queue.get_nowait()
                    frame_queue.task_done()
                except Exception:
                    pass
            frame_queue.put_nowait(frame)
        except queue.Full:
            pass

        # tight wait key to keep display smooth
        if cv2.waitKey(1) & 0xFF == 27:
            break

finally:
    running = False
    try:
        while not frame_queue.empty():
            frame_queue.get_nowait()
            frame_queue.task_done()
    except Exception:
        pass

    worker.join(timeout=1.0)
    cap.release()
    cv2.destroyAllWindows()
    print("Exited cleanly.")
