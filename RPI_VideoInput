#!/usr/bin/env python3
import os
import torch
import cv2
from ultralytics import YOLO
import time
import tkinter as tk
from tkinter import filedialog
import threading
import queue

# -------------------------- Fix for PyTorch 2.6+ weights loading --------------------------
orig_torch_load = torch.load
def torch_load_wrapper(*args, **kwargs):
    kwargs["weights_only"] = False
    return orig_torch_load(*args, **kwargs)
torch.load = torch_load_wrapper

# -------------------------- MODEL PATHS (fill these with your .pt files on the Pi) ----------
PIG_MODEL_PATH = "/home/asfrotect/Projects/pig_vs_non_pig.v3.pt"
ASF_MODEL_PATH = "/home/asfrotect/Projects/best(ASF_MODEL)_.pt"
BEHAVIOR_MODEL_PATH = "/home/asfrotect/Projects/best(BEHAVIOR_MODEL)_.pt"

# -------------------------- Settings (tweak these) --------------------------
DETECTION_INTERVAL = 3.0          # seconds between full detections (and how long boxes remain visible)
# Optionally resize frames BEFORE sending to detection worker to speed up inference.
# Set to None to keep original size, or (width, height) e.g. (640,360)
RESIZE_FOR_DETECTION = (640,360)

# -------------------------- Choose video file via file dialog --------------------------
def choose_video_file():
    root = tk.Tk()
    root.withdraw()  # hide main window
    root.attributes("-topmost", True)  # bring dialog on top
    file_path = filedialog.askopenfilename(
        title="Select video file",
        filetypes=[("Video files", "*.mp4 *.avi *.mov *.mkv"), ("All files", "*.*")]
    )
    root.destroy()
    return file_path

video_path = choose_video_file()
if not video_path:
    print("No video file selected. Exiting.")
    exit()

if not os.path.isfile(video_path):
    print(f"Selected file does not exist: {video_path}")
    exit()

print(f"Selected video: {video_path}")

# -------------------------- Load YOLOv8 models (only if paths provided) ----------
def load_model_or_none(path, model_name):
    if path and os.path.isfile(path):
        print(f"Loading {model_name} model from: {path}")
        return YOLO(path)
    else:
        print(f"[WARN] {model_name} model path not provided or file missing. {model_name} detection will be skipped.")
        return None

pig_model = load_model_or_none(PIG_MODEL_PATH, "Pig")
asf_model = load_model_or_none(ASF_MODEL_PATH, "ASF")
behavior_model = load_model_or_none(BEHAVIOR_MODEL_PATH, "Behavior")

if pig_model is None:
    print("Error: Pig model is required. Put your pig model path in PIG_MODEL_PATH and restart.")
    exit()

# -------------------------- Open video file ----------
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("Error: Could not open video file.")
    exit()

# -------------------------- Helper functions --------------------------
def draw_label(frame, box, label, color=(0,255,0)):
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    (w_text, h_text), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
    cv2.rectangle(frame, (x1, y1 - h_text - 8), (x1 + w_text + 6, y1), color, -1)
    cv2.putText(frame, label, (x1 + 3, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)

def box_inside(boxA, boxB):
    ax1, ay1, ax2, ay2 = map(int, boxA)
    bx1, by1, bx2, by2 = map(int, boxB)
    return ax1 >= bx1 and ay1 >= by1 and ax2 <= bx2 and ay2 <= by2

# -------------------------- Detection scheduling + worker --------------------------
detection_queue = queue.Queue(maxsize=1)   # 1-slot queue (drop-old policy)
annotated_lock = threading.Lock()
annotated_boxes = []   # list of tuples: (box_coords, label, color)
expiry_time = 0.0
running = True

def detection_worker():
    global annotated_boxes, expiry_time, running
    while running:
        try:
            frame_for_detection = detection_queue.get(timeout=0.5)
        except queue.Empty:
            continue

        # optionally resize for faster inference
        if RESIZE_FOR_DETECTION is not None:
            frame_small = cv2.resize(frame_for_detection, RESIZE_FOR_DETECTION)
        else:
            frame_small = frame_for_detection

        # ensure 3-channel uint8
        src = frame_small
        if src.ndim == 3 and src.shape[2] == 4:
            src = src[..., :3]
        src = src.astype('uint8')

        boxes_out = []  # collect (coords, label, color)

        # ---------- Step 1: Detect pigs ----------
        pig_results = pig_model.predict(source=src, conf=0.3, save=False, show=False, verbose=False)
        pig_boxes = []
        for r in pig_results:
            for box in r.boxes:
                try:
                    cls_id = int(box.cls[0].item()); conf = float(box.conf[0].item())
                except Exception:
                    cls_id = int(box.cls); conf = float(box.conf)
                if conf < 0.3:
                    continue
                label = r.names.get(cls_id, str(cls_id)) if hasattr(r, "names") else str(cls_id)
                if "pig" in label.lower():
                    pig_boxes.append((box, conf))

        # Map coordinates back to original frame size if resized
        scale_x = 1.0
        scale_y = 1.0
        if RESIZE_FOR_DETECTION is not None:
            orig_h, orig_w = frame_for_detection.shape[:2]
            small_w, small_h = RESIZE_FOR_DETECTION
            scale_x = orig_w / small_w
            scale_y = orig_h / small_h

        # ---------- Step 2: For each pig, detect ASF lesions and behavior ----------
        for pig_box, pig_conf in pig_boxes:
            bx1, by1, bx2, by2 = map(int, pig_box.xyxy[0])
            # if resized, rescale pig box to original coordinates
            if RESIZE_FOR_DETECTION is not None:
                bx1 = int(bx1 * scale_x)
                by1 = int(by1 * scale_y)
                bx2 = int(bx2 * scale_x)
                by2 = int(by2 * scale_y)

            # crop from original-size coordinates for ASF/behavior (better accuracy)
            # careful with bounds
            orig_h, orig_w = frame_for_detection.shape[:2]
            x1, y1, x2, y2 = max(0, bx1), max(0, by1), min(orig_w - 1, bx2), min(orig_h - 1, by2)
            pig_crop = frame_for_detection[y1:y2, x1:x2]
            if pig_crop.size == 0:
                continue

            # ASF detection
            lesion_boxes = []
            part_boxes = []
            if asf_model is not None:
                asf_results = asf_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                for r in asf_results:
                    for a_box in r.boxes:
                        try:
                            cls_id = int(a_box.cls[0].item()); conf = float(a_box.conf[0].item())
                        except Exception:
                            cls_id = int(a_box.cls); conf = float(a_box.conf)
                        if conf < 0.5:
                            continue
                        label = r.names[cls_id]
                        ax1, ay1, ax2, ay2 = map(int, a_box.xyxy[0])
                        # map crop coords back to original frame coords
                        ax1, ay1, ax2, ay2 = ax1 + x1, ay1 + y1, ax2 + x1, ay2 + y1
                        if "lesion" in label.lower():
                            lesion_boxes.append((ax1, ay1, ax2, ay2))
                        elif label.lower() in ["ear", "leg", "nose", "tail"]:
                            part_boxes.append((ax1, ay1, ax2, ay2, label))

            # Behavior detection
            behavior_label = None
            if behavior_model is not None:
                behavior_results = behavior_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                for r in behavior_results:
                    for b_box in r.boxes:
                        try:
                            cls_id = int(b_box.cls[0].item()); conf = float(b_box.conf[0].item())
                        except Exception:
                            cls_id = int(b_box.cls); conf = float(b_box.conf)
                        if conf >= 0.5:
                            behavior_label = r.names[cls_id]
                            break
                    if behavior_label:
                        break

            behavior_label_full = f"pig-{pig_conf:.2f}-{behavior_label.lower()}" if behavior_label else f"pig-{pig_conf:.2f}"

            # append pig box + behavior label (green)
            boxes_out.append(((x1, y1, x2, y2), behavior_label_full, (0,255,0)))

            # append lesion boxes (red) with merged labels if overlapping parts
            for lesion in lesion_boxes:
                merged_label = "possible skin lesion"
                for (px1, py1, px2, py2, part_label) in part_boxes:
                    if box_inside(lesion, (px1, py1, px2, py2)):
                        merged_label = f"possible skin lesion - {part_label.lower()}"
                        break
                boxes_out.append((lesion, merged_label, (0,0,255)))

        # store results and set expiry
        with annotated_lock:
            annotated_boxes = boxes_out
            expiry_time = time.time() + DETECTION_INTERVAL

        try:
            detection_queue.task_done()
        except Exception:
            pass

# start detection worker thread
worker = threading.Thread(target=detection_worker, daemon=True)
worker.start()

# force first detection immediately (so user sees boxes quickly)
last_detection_request = -DETECTION_INTERVAL

# -------------------------- Main processing loop (display every frame) --------------------------
frame_count = 0
fps_time = time.time()

try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("End of video or failed to read frame.")
            break

        frame_count += 1
        im_bgr = frame.copy()

        # Draw annotated boxes if within expiry
        now = time.time()
        with annotated_lock:
            current_boxes = annotated_boxes.copy()
            current_expiry = expiry_time

        if now <= current_expiry and current_boxes:
            for (box_coords, label, color) in current_boxes:
                draw_label(im_bgr, box_coords, label, color=color)

        # Display FPS (measured per displayed frame)
        now2 = time.time()
        fps = 1.0 / (now2 - fps_time) if (now2 - fps_time) > 0 else 0.0
        fps_time = now2
        cv2.putText(im_bgr, f"FPS: {fps:.1f}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)

        cv2.imshow("Pig + ASF + Behavior Detection", im_bgr)

        # Request detection every DETECTION_INTERVAL seconds (non-blocking push)
        if (now - last_detection_request) >= DETECTION_INTERVAL:
            try:
                # prepare frame_for_detection: optionally resize to speed inference
                frame_to_queue = frame.copy()
                if RESIZE_FOR_DETECTION is not None:
                    frame_to_queue = cv2.resize(frame_to_queue, RESIZE_FOR_DETECTION)
                # drop-old and push latest
                if detection_queue.full():
                    try:
                        _ = detection_queue.get_nowait()
                        detection_queue.task_done()
                    except Exception:
                        pass
                detection_queue.put_nowait(frame_to_queue if RESIZE_FOR_DETECTION is not None else frame.copy())
                last_detection_request = now
            except queue.Full:
                pass

        # Press ESC to exit early
        if cv2.waitKey(1) & 0xFF == 27:
            break

finally:
    running = False
    try:
        while not detection_queue.empty():
            detection_queue.get_nowait()
            detection_queue.task_done()
    except Exception:
        pass
    worker.join(timeout=1.0)
    cap.release()
    cv2.destroyAllWindows()
    print("Exited cleanly.")

