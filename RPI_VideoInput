#!/usr/bin/env python3
import os
import torch
import cv2
from ultralytics import YOLO
import time
import tkinter as tk
from tkinter import filedialog

# -------------------------- Fix for PyTorch 2.6+ weights loading --------------------------
orig_torch_load = torch.load
def torch_load_wrapper(*args, **kwargs):
    kwargs["weights_only"] = False
    return orig_torch_load(*args, **kwargs)
torch.load = torch_load_wrapper

# -------------------------- MODEL PATHS (fill these with your .pt files on the Pi) ----------
PIG_MODEL_PATH = "/home/asfrotect/Projects/pig_vs_non_pig.v3.pt"
ASF_MODEL_PATH = "/home/asfrotect/Projects/best(ASF_MODEL)_.pt"
BEHAVIOR_MODEL_PATH = "/home/asfrotect/Projects/best(BEHAVIOR_MODEL)_.pt"

# -------------------------- Settings --------------------------
DETECTION_INTERVAL = 3.0   # seconds between full detections and how long boxes remain visible
# If your Pi is slow, set RESIZE_FOR_DETECTION to (640,360) or similar to speed up inference.
RESIZE_FOR_DETECTION = None  # or (640,360)
DEBUG = False               # set True to print debug info

# -------------------------- Choose video file via file dialog --------------------------
def choose_video_file():
    root = tk.Tk()
    root.withdraw()
    root.attributes("-topmost", True)
    file_path = filedialog.askopenfilename(
        title="Select video file",
        filetypes=[("Video files", "*.mp4 *.avi *.mov *.mkv"), ("All files", "*.*")]
    )
    root.destroy()
    return file_path

video_path = choose_video_file()
if not video_path:
    print("No video file selected. Exiting.")
    exit()

if not os.path.isfile(video_path):
    print(f"Selected file does not exist: {video_path}")
    exit()

print(f"Selected video: {video_path}")

# -------------------------- Load YOLOv8 models (only if paths provided) ----------
def load_model_or_none(path, model_name):
    if path and os.path.isfile(path):
        print(f"Loading {model_name} model from: {path}")
        try:
            m = YOLO(path)
            print(f"[OK] {model_name} model loaded.")
            return m
        except Exception as e:
            print(f"[ERROR] Failed to load {model_name} model: {e}")
            return None
    else:
        print(f"[WARN] {model_name} model path not provided or file missing. {model_name} detection will be skipped.")
        return None

pig_model = load_model_or_none(PIG_MODEL_PATH, "Pig")
asf_model = load_model_or_none(ASF_MODEL_PATH, "ASF")
behavior_model = load_model_or_none(BEHAVIOR_MODEL_PATH, "Behavior")

if pig_model is None:
    print("Error: Pig model is required. Put your pig model path in PIG_MODEL_PATH and restart.")
    exit()

# -------------------------- Open video file ----------
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("Error: Could not open video file.")
    exit()

# -------------------------- Helper functions --------------------------
def draw_label(frame, box, label, color=(0,255,0)):
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    (w_text, h_text), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
    cv2.rectangle(frame, (x1, y1 - h_text - 8), (x1 + w_text + 6, y1), color, -1)
    cv2.putText(frame, label, (x1 + 3, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)

def box_inside(boxA, boxB):
    ax1, ay1, ax2, ay2 = map(int, boxA)
    bx1, by1, bx2, by2 = map(int, boxB)
    return ax1 >= bx1 and ay1 >= by1 and ax2 <= bx2 and ay2 <= by2

# -------------------------- Detection bookkeeping --------------------------
last_detection_time = -DETECTION_INTERVAL   # force immediate detection at start
annotated_boxes = []    # list of tuples: (coords, label, color)
expiry_time = 0.0

# -------------------------- FPS averaging (1-second window) --------------------------
last_fps_time = time.time()
frame_counter_for_fps = 0
display_fps = 0.0

print("[INFO] Starting processing loop. Press ESC to stop.")

try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("End of video or failed to read frame.")
            break

        now = time.time()

        # if it's time to detect, run detection synchronously (keeps original logic intact)
        if (now - last_detection_time) >= DETECTION_INTERVAL:
            # prepare frame for detection (optionally resize to speed up)
            if RESIZE_FOR_DETECTION is not None:
                frame_for_detection = cv2.resize(frame.copy(), RESIZE_FOR_DETECTION)
            else:
                frame_for_detection = frame.copy()

            # STEP 1: Detect pigs (same as your original)
            try:
                pig_results = pig_model.predict(source=frame_for_detection, conf=0.3, save=False, show=False, verbose=False)
            except Exception as e:
                print(f"[ERROR] pig_model.predict failed: {e}")
                pig_results = []

            pig_boxes = []
            try:
                for r in pig_results:
                    for box in r.boxes:
                        try:
                            cls_id = int(box.cls[0].item())
                            conf = float(box.conf[0].item())
                        except Exception:
                            cls_id = int(box.cls)
                            conf = float(box.conf)
                        if conf < 0.3:
                            continue
                        label = r.names.get(cls_id, str(cls_id)) if hasattr(r, "names") else str(cls_id)
                        if "pig" in label.lower():
                            pig_boxes.append((box, conf))
            except Exception as e:
                print(f"[ERROR] parsing pig_results: {e}")
                pig_boxes = []

            # prepare new annotated list
            new_annotated = []

            # If we resized for detection, compute rescale factors to map boxes back to original frame
            scale_x = 1.0
            scale_y = 1.0
            if RESIZE_FOR_DETECTION is not None:
                orig_h, orig_w = frame.shape[:2]
                small_w, small_h = RESIZE_FOR_DETECTION
                scale_x = orig_w / small_w
                scale_y = orig_h / small_h

            # STEP 2: For each pig, run ASF + behavior (unchanged)
            for pig_box, pig_conf in pig_boxes:
                bx1, by1, bx2, by2 = map(int, pig_box.xyxy[0])
                if RESIZE_FOR_DETECTION is not None:
                    bx1 = int(bx1 * scale_x)
                    by1 = int(by1 * scale_y)
                    bx2 = int(bx2 * scale_x)
                    by2 = int(by2 * scale_y)

                h_frame, w_frame = frame.shape[:2]
                x1, y1 = max(0, bx1), max(0, by1)
                x2, y2 = min(w_frame - 1, bx2), min(h_frame - 1, by2)
                pig_crop = frame[y1:y2, x1:x2]
                if pig_crop.size == 0:
                    continue

                # ASF detection
                lesion_boxes = []
                part_boxes = []
                if asf_model is not None:
                    try:
                        asf_results = asf_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                    except Exception as e:
                        print(f"[ERROR] asf_model.predict failed: {e}")
                        asf_results = []
                    try:
                        for r in asf_results:
                            for a_box in r.boxes:
                                try:
                                    cls_id = int(a_box.cls[0].item())
                                    conf = float(a_box.conf[0].item())
                                except Exception:
                                    cls_id = int(a_box.cls)
                                    conf = float(a_box.conf)
                                if conf < 0.5:
                                    continue
                                label = r.names[cls_id]
                                ax1, ay1, ax2, ay2 = map(int, a_box.xyxy[0])
                                # map crop coords back to original frame coords
                                ax1, ay1, ax2, ay2 = ax1 + x1, ay1 + y1, ax2 + x1, ay2 + y1
                                if "lesion" in label.lower():
                                    lesion_boxes.append((ax1, ay1, ax2, ay2))
                                elif label.lower() in ["ear", "leg", "nose", "tail"]:
                                    part_boxes.append((ax1, ay1, ax2, ay2, label))
                    except Exception as e:
                        print(f"[ERROR] parsing asf_results: {e}")

                # Behavior detection
                behavior_label = None
                if behavior_model is not None:
                    try:
                        behavior_results = behavior_model.predict(source=pig_crop, conf=0.5, save=False, show=False, verbose=False)
                    except Exception as e:
                        print(f"[ERROR] behavior_model.predict failed: {e}")
                        behavior_results = []
                    try:
                        for r in behavior_results:
                            for b_box in r.boxes:
                                try:
                                    cls_id = int(b_box.cls[0].item())
                                    conf = float(b_box.conf[0].item())
                                except Exception:
                                    cls_id = int(b_box.cls)
                                    conf = float(b_box.conf)
                                if conf >= 0.5:
                                    behavior_label = r.names[cls_id]
                                    break
                            if behavior_label:
                                break
                    except Exception as e:
                        print(f"[ERROR] parsing behavior_results: {e}")

                behavior_label_full = f"pig-{pig_conf:.2f}-{behavior_label.lower()}" if behavior_label else f"pig-{pig_conf:.2f}"

                # append pig box + behavior label (green)
                new_annotated.append(((x1, y1, x2, y2), behavior_label_full, (0,255,0)))

                # append lesion boxes (red)
                for lesion in lesion_boxes:
                    merged_label = "possible skin lesion"
                    for (px1, py1, px2, py2, part_label) in part_boxes:
                        if box_inside(lesion, (px1, py1, px2, py2)):
                            merged_label = f"possible skin lesion - {part_label.lower()}"
                            break
                    new_annotated.append((lesion, merged_label, (0,0,255)))

            annotated_boxes = new_annotated
            expiry_time = now + DETECTION_INTERVAL
            last_detection_time = now

            if DEBUG:
                print(f"[DETECT] ran detection @ {time.strftime('%H:%M:%S')}, boxes: {len(annotated_boxes)}")

        # Prepare display
        im_bgr = frame.copy()

        # draw boxes if still within expiry
        if time.time() <= expiry_time and annotated_boxes:
            for (coords, label, color) in annotated_boxes:
                draw_label(im_bgr, coords, label, color=color)

        # FPS averaging over 1 second window
        frame_counter_for_fps += 1
        t_now = time.time()
        elapsed = t_now - last_fps_time
        if elapsed >= 1.0:
            display_fps = frame_counter_for_fps / elapsed
            frame_counter_for_fps = 0
            last_fps_time = t_now

        cv2.putText(im_bgr, f"FPS: {display_fps:.1f}", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)

        cv2.imshow("Pig + ASF + Behavior Detection", im_bgr)

        # Press ESC to exit early
        if cv2.waitKey(1) & 0xFF == 27:
            break

finally:
    cap.release()
    cv2.destroyAllWindows()
    print("Exited cleanly.")
