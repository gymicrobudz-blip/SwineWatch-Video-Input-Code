import cv2
import numpy as np
import time

from tflite_runtime.interpreter import Interpreter
from picamera2 import Picamera2

# ================= CONFIG =================
IMG_SIZE = 416

PIG_MODEL = "/home/asfrotect/Projects/BYMS - TFLITE 3 COMBINED/PigvsNONPig-v2_float16.tflite"
BEHAVIOR_MODEL = "/home/asfrotect/Projects/BYMS - TFLITE 3 COMBINED/bestv8_behavior-2_float16.tflite"
SKIN_MODEL = "/home/asfrotect/Projects/BYMS - TFLITE 3 COMBINED/ASFskin_NoPartsv3_v8s.tflite"

PIG_CLASS_ID = 7
HUMAN_CLASS_ID = 0

PIG_CONF = 0.50
SKIN_CONF = 0.45

BEHAVIOR_INTERVAL = 3
SKIN_INTERVAL = 1

# ================= LABELS =================
BEHAVIOR_NAMES = {
    0: "ACTIVE",
    1: "EATING",
    2: "GROUP",
    3: "INACTIVE"
}

SKIN_NAMES = {
    1: "ASF LESION",
    2: "REDNESS"
}

# ================= HELPERS =================
def preprocess(img):
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img.astype(np.float32) / 255.0
    return img[np.newaxis, ...]

def compute_iou(a, b):
    xA, yA = max(a[0], b[0]), max(a[1], b[1])
    xB, yB = min(a[2], b[2]), min(a[3], b[3])
    inter = max(0, xB - xA) * max(0, yB - yA)
    areaA = max(0, a[2]-a[0]) * max(0, a[3]-a[1])
    areaB = max(0, b[2]-b[0]) * max(0, b[3]-b[1])
    return inter / (areaA + areaB - inter + 1e-6)

def nms(dets, thresh):
    dets = sorted(dets, key=lambda x: x[1], reverse=True)
    keep = []
    while dets:
        best = dets.pop(0)
        keep.append(best)
        dets = [d for d in dets if compute_iou(best[0], d[0]) < thresh]
    return keep

def overlaps_any(box, boxes, thresh=0.25):
    for b in boxes:
        if compute_iou(box, b) > thresh:
            return True
    return False

def load_model(path):
    itp = Interpreter(model_path=path)
    itp.allocate_tensors()
    return itp

# ================= LOAD MODELS =================
pig_itp = load_model(PIG_MODEL)
beh_itp = load_model(BEHAVIOR_MODEL)
skin_itp = load_model(SKIN_MODEL)

pig_in, pig_out = pig_itp.get_input_details(), pig_itp.get_output_details()
beh_in, beh_out = beh_itp.get_input_details(), beh_itp.get_output_details()
skin_in, skin_out = skin_itp.get_input_details(), skin_itp.get_output_details()

# ================= PI CAMERA =================
picam2 = Picamera2()
config = picam2.create_preview_configuration(
    main={"format": "BGR888", "size": (640, 480)}
)
picam2.configure(config)
picam2.start()

frame_id = 0
fps_time = time.time()
last_behavior = "INACTIVE"

# ================= MAIN LOOP =================
while True:
    frame = picam2.capture_array()
    frame = cv2.flip(frame, 0)

    frame_id += 1
    H, W, _ = frame.shape

    pigs = []
    human_boxes = []

    # -------- PIG + HUMAN --------
    pig_itp.set_tensor(pig_in[0]['index'], preprocess(frame))
    pig_itp.invoke()
    preds = pig_itp.get_tensor(pig_out[0]['index'])[0].T

    for d in preds:
        x, y, bw, bh = d[:4]
        scores = d[4:]
        cid = int(np.argmax(scores))
        conf = float(scores[cid])

        if conf < PIG_CONF:
            continue

        x1 = int((x - bw/2) * W)
        y1 = int((y - bh/2) * H)
        x2 = int((x + bw/2) * W)
        y2 = int((y + bh/2) * H)

        if cid == PIG_CLASS_ID:
            pigs.append(((x1,y1,x2,y2), conf))
        elif cid == HUMAN_CLASS_ID:
            human_boxes.append((x1,y1,x2,y2))

    pigs = nms(pigs, 0.4)

    # -------- BEHAVIOR --------
    for (x1,y1,x2,y2), pconf in pigs:
        roi = frame[max(0,y1):min(H,y2), max(0,x1):min(W,x2)]
        if roi.size == 0:
            continue

        if frame_id % BEHAVIOR_INTERVAL == 0:
            beh_itp.set_tensor(beh_in[0]['index'], preprocess(roi))
            beh_itp.invoke()
            outs = beh_itp.get_tensor(beh_out[0]['index'])[0].T
            best = max(outs, key=lambda d: max(d[4:]))
            last_behavior = BEHAVIOR_NAMES[int(np.argmax(best[4:]))]

        cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)
        cv2.putText(
            frame,
            f"PIG {pconf:.2f} | {last_behavior}",
            (x1, max(0,y1-8)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.45,
            (0,255,0),
            1
        )

    # -------- SKIN (NO TRACKING) --------
    if frame_id % SKIN_INTERVAL == 0:
        skin_itp.set_tensor(skin_in[0]['index'], preprocess(frame))
        skin_itp.invoke()
        outs = skin_itp.get_tensor(skin_out[0]['index'])[0].T

        for d in outs:
            x,y,bw,bh = d[:4]
            scores = d[4:]
            cid = int(np.argmax(scores))
            conf = float(scores[cid])

            if cid not in SKIN_NAMES or conf < SKIN_CONF:
                continue

            x1 = int((x - bw/2) * W)
            y1 = int((y - bh/2) * H)
            x2 = int((x + bw/2) * W)
            y2 = int((y + bh/2) * H)

            if overlaps_any((x1,y1,x2,y2), human_boxes):
                continue

            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255),2)
            cv2.putText(
                frame,
                f"{SKIN_NAMES[cid]} {conf:.2f}",
                (x1,y1-4),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.4,
                (0,0,255),
                1
            )

    # -------- FPS --------
    now = time.time()
    fps = 1.0 / max(1e-6, now - fps_time)
    fps_time = now

    cv2.putText(frame, f"FPS: {fps:.1f}", (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2)

    cv2.imshow("ASF DETECTION ONLY - PI", frame)
    if cv2.waitKey(1) == 27:
        break

picam2.stop()
cv2.destroyAllWindows()
